{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261fb61c",
   "metadata": {},
   "source": [
    "# Wine Quality Prediction\n",
    "\n",
    "딥러닝에서 학습한 내용을 바탕으로 Wine quality 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc653d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "input_file = \"winequality-red.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "df = shuffle(df, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2482836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop([\"quality\"], axis=1)\n",
    "y_train = df[\"quality\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df272f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[11]),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(256, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "#         keras.layers.Dense(128, activation=\"selu\"),\n",
    "#         keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(32, activation=\"selu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "    # loss = ???\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62557b0",
   "metadata": {},
   "source": [
    "**epoch 100**\n",
    "\n",
    "0.41588044762611387 (128, 64, 32), 100\n",
    "\n",
    "0.413698747754097 (128, 64), 100\n",
    "\n",
    "0.42252110242843627 (256, 64), 100\n",
    "\n",
    "0.4164641261100769 (256, 16), 100\n",
    "\n",
    "0.41348819732666015 (256, 64, 32), 100\n",
    "\n",
    "0.4162064105272293 (256, 128, 64), 100\n",
    "\n",
    "0.44471500217914584 (512, 256) 100\n",
    "\n",
    "0.4069845587015152 (64, 32, 16), 100\n",
    "\n",
    "0.40831289887428285 (64, 32), 100\n",
    "\n",
    "0.40444025695323943 (128, 32), 100\n",
    "\n",
    "0.40088256895542146 (256, 32), 100\n",
    "\n",
    "0.3934067189693451 (256, 32), 1000\n",
    "\n",
    "0.3979105710983276 (256, 32), 100, rs = 0, ts = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b025b",
   "metadata": {},
   "source": [
    "**Epoch를 0부터 증가**\n",
    "\n",
    "172.41917667388915\n",
    "21.945555210113525\n",
    "17.852294921875\n",
    "12.66164951324463\n",
    "8.696906757354736\n",
    "5.377784085273743\n",
    "1.9896422386169434\n",
    "1.1584799140691757\n",
    "0.7740994483232498\n",
    "0.6311340183019638\n",
    "0.6141884416341782\n",
    "0.5908999562263488\n",
    "0.5627762675285339\n",
    "0.518043315410614\n",
    "0.5519967973232269\n",
    "0.5065222889184952\n",
    "0.48082537949085236\n",
    "0.4987828701734543\n",
    "0.554146271944046\n",
    "0.47364491820335386\n",
    "0.4813063532114029\n",
    "0.468992218375206\n",
    "0.4569897323846817\n",
    "0.4429522305727005\n",
    "0.46153414249420166\n",
    "0.47999241650104524\n",
    "0.4722131997346878\n",
    "0.4497163385152817\n",
    "0.4955722391605377\n",
    "0.4993168294429779\n",
    "0.4351538628339767\n",
    "0.44021921455860136\n",
    "0.4382027447223663\n",
    "0.45399969816207886\n",
    "0.45706278681755064\n",
    "0.4562686264514923\n",
    "0.44031307101249695\n",
    "0.4552554041147232\n",
    "0.47077620923519137\n",
    "0.4425239533185959\n",
    "0.4416780799627304\n",
    "0.4591837465763092\n",
    "0.4476312816143036\n",
    "0.46602498888969424\n",
    "0.42522813379764557\n",
    "0.43731707632541655\n",
    "0.45406066477298734\n",
    "0.4390187978744507\n",
    "0.44486366510391234\n",
    "0.4301999568939209\n",
    "0.4342657715082169\n",
    "0.4452052503824234\n",
    "0.45197419822216034\n",
    "0.4256725162267685\n",
    "0.43618726134300234\n",
    "0.44309957325458527\n",
    "0.43470293283462524\n",
    "0.439967679977417\n",
    "0.4187764436006546\n",
    "0.44971288442611695\n",
    "0.4202736377716064\n",
    "0.4243598848581314\n",
    "0.43456884026527404\n",
    "0.4169876664876938\n",
    "0.42497742772102354\n",
    "0.43851353228092194\n",
    "0.4204429477453232\n",
    "0.42097243666648865\n",
    "0.4277280122041702\n",
    "0.4287666857242584\n",
    "0.4100036084651947\n",
    "0.41244590282440186\n",
    "0.41413313448429107\n",
    "0.4222682058811188\n",
    "0.4044589400291443\n",
    "0.42844395339488983\n",
    "0.42119531631469725\n",
    "0.423619756102562\n",
    "0.4148988276720047\n",
    "0.4232701689004898\n",
    "0.43615598380565646\n",
    "0.42092215418815615\n",
    "0.4288894921541214\n",
    "0.4334784150123596\n",
    "0.4234389394521713\n",
    "0.4117216855287552\n",
    "0.40667464435100553\n",
    "0.4157992959022522\n",
    "0.41282397210597993\n",
    "0.41412420868873595\n",
    "0.4025042712688446\n",
    "0.4147683590650558\n",
    "0.4247572302818298\n",
    "0.43587263822555544\n",
    "0.4387808799743652\n",
    "0.4156281888484955\n",
    "0.43122042417526246\n",
    "0.4344989538192749\n",
    "0.407373183965683\n",
    "0.410164937376976\n",
    "0.3979105710983276\n",
    "0.4187539368867874\n",
    "0.41260315477848053\n",
    "0.4292067587375641\n",
    "0.399809741973877\n",
    "0.41063263416290285\n",
    "0.4280294865369797\n",
    "0.4221940070390701\n",
    "0.41790902316570283\n",
    "0.436898010969162\n",
    "0.4173701465129852\n",
    "0.42727656960487365\n",
    "0.4010824143886566\n",
    "0.4009511172771454\n",
    "0.41499831080436705\n",
    "0.408322736620903\n",
    "0.42454600930213926\n",
    "0.4228956997394562\n",
    "0.42603283524513247\n",
    "0.4079179048538208\n",
    "0.42088590264320375\n",
    "0.4196155369281769\n",
    "0.41848075687885283\n",
    "0.42067878544330595\n",
    "0.41931498646736143\n",
    "0.4278150737285614\n",
    "0.4214520901441574\n",
    "0.4141284853219986\n",
    "0.42357429265975954\n",
    "0.4156737834215164\n",
    "0.41132116317749023\n",
    "0.4179798632860184\n",
    "0.4133115947246552\n",
    "0.4191304683685303\n",
    "0.4100912243127823\n",
    "0.4213832229375839\n",
    "0.4074562668800354\n",
    "0.4121223330497742\n",
    "0.419791117310524\n",
    "0.41072062849998475\n",
    "0.41223941147327425\n",
    "0.4141568124294281\n",
    "0.4063525438308716\n",
    "0.4181923449039459\n",
    "0.4109313488006592\n",
    "0.4108400732278824\n",
    "0.41960820853710173\n",
    "0.41442251205444336\n",
    "0.4167929947376251\n",
    "0.4120543599128723\n",
    "0.40082830786705015\n",
    "0.41463789641857146\n",
    "0.40647159814834594\n",
    "0.43103246092796327\n",
    "0.40391032099723817\n",
    "0.4128672510385513\n",
    "0.41636218726634977\n",
    "0.4229824900627136\n",
    "0.41813899874687194\n",
    "0.41258991658687594\n",
    "0.39405257999897003\n",
    "0.4053231984376907\n",
    "0.4216957241296768\n",
    "0.4007810682058334\n",
    "0.40166408121585845\n",
    "0.40473920702934263\n",
    "0.4139799177646637\n",
    "0.4060384452342987\n",
    "0.4118736296892166\n",
    "0.4138522773981094\n",
    "0.40933412313461304\n",
    "0.40558934211730957\n",
    "0.4138332962989807\n",
    "0.40986179411411283\n",
    "0.4145868241786957\n",
    "0.4011273354291916\n",
    "0.40412578284740447\n",
    "0.4025247931480408\n",
    "0.4071572065353394\n",
    "0.4056925505399704\n",
    "0.396848526597023\n",
    "0.43244514167308806\n",
    "0.4210231781005859\n",
    "0.41785319745540617\n",
    "0.4022897779941559\n",
    "0.3975302428007126\n",
    "0.4181161761283875\n",
    "0.3920974314212799\n",
    "0.40328758060932157\n",
    "0.4167837917804718\n",
    "0.39537353515625\n",
    "0.3941810607910156\n",
    "0.3944553375244141\n",
    "0.3985123306512833\n",
    "0.40400809347629546\n",
    "0.410740453004837\n",
    "0.4257147043943405\n",
    "0.3970257997512817\n",
    "0.3960623860359192\n",
    "0.39741947054862975\n",
    "0.4001889765262604\n",
    "0.4076183557510376\n",
    "0.40616564750671386\n",
    "0.4097183495759964\n",
    "0.3937754243612289\n",
    "0.40170512199401853\n",
    "0.4183286100625992\n",
    "0.40123982429504396\n",
    "0.3935456782579422\n",
    "0.43023703396320345\n",
    "0.39938671290874483\n",
    "0.40222428143024447\n",
    "0.4116550415754318\n",
    "0.41492596864700315\n",
    "0.404631519317627\n",
    "0.3961277723312378\n",
    "0.4083277702331543\n",
    "0.4083301186561584\n",
    "0.40423222780227663\n",
    "0.4160701811313629\n",
    "0.4046593189239502\n",
    "0.39880249202251433\n",
    "0.3968792885541916\n",
    "0.40423139929771423\n",
    "0.41310918629169463\n",
    "0.40666945576667785\n",
    "0.40043442249298095\n",
    "0.4012302577495575\n",
    "0.422734808921814\n",
    "0.40584502220153806\n",
    "0.425203800201416\n",
    "0.3987527400255203\n",
    "0.40699244737625123\n",
    "0.40352984368801115\n",
    "0.4303402453660965\n",
    "0.41164960265159606\n",
    "0.40115670263767245\n",
    "0.43068972527980803\n",
    "0.4123671919107437\n",
    "0.4172178000211716\n",
    "0.4171262264251709\n",
    "0.4469078600406647\n",
    "0.4188831508159637\n",
    "0.39495896697044375\n",
    "0.3987573027610779\n",
    "0.39403643012046813\n",
    "0.40298905074596403\n",
    "0.40323484838008883\n",
    "0.417535138130188\n",
    "0.40171619355678556\n",
    "0.40527646243572235\n",
    "0.4133309662342072\n",
    "0.3978686839342117\n",
    "0.4049002856016159\n",
    "0.40322624444961547\n",
    "0.40673930048942564\n",
    "0.41497582793235777\n",
    "0.40117294192314146\n",
    "0.4101818799972534\n",
    "0.4051619827747345\n",
    "0.4020459592342377\n",
    "0.39839079082012174\n",
    "0.4056776374578476\n",
    "0.4064262568950653\n",
    "0.4083319216966629\n",
    "0.40197150111198426\n",
    "0.39847451746463775\n",
    "0.39755081236362455\n",
    "0.395709428191185\n",
    "0.41454939544200897\n",
    "0.40503025949001314\n",
    "0.40192650258541107\n",
    "0.3952580064535141\n",
    "0.39935409724712373\n",
    "0.4214126646518707\n",
    "0.3949164539575577\n",
    "0.3978978514671326\n",
    "0.4016546130180359\n",
    "0.40722928047180174\n",
    "0.39912022054195406\n",
    "0.4018509566783905\n",
    "0.3896151721477509\n",
    "0.41227114498615264\n",
    "0.40867980718612673\n",
    "0.38668836653232574\n",
    "0.4039794564247131\n",
    "0.40391147434711455\n",
    "0.40950171947479247\n",
    "0.4054815858602524\n",
    "0.40014922320842744\n",
    "0.409587687253952\n",
    "0.4021758884191513\n",
    "0.4149257093667984\n",
    "0.407859206199646\n",
    "0.4113188683986664\n",
    "0.40518766939640044\n",
    "0.43184223771095276\n",
    "0.4046171247959137\n",
    "0.40206597149372103\n",
    "0.40889366567134855\n",
    "0.3935640662908554\n",
    "0.40789749622344973\n",
    "0.4120251327753067\n",
    "0.40811253190040586\n",
    "0.42230284214019775\n",
    "0.4118779867887497\n",
    "0.4247067511081696\n",
    "0.40165520310401914\n",
    "0.3959056049585342\n",
    "0.3945780724287033\n",
    "0.40254838168621065\n",
    "0.40810502171516416\n",
    "0.40127243399620055\n",
    "0.41000059247016907\n",
    "0.405438169836998\n",
    "0.4085216552019119\n",
    "0.4104758590459824\n",
    "0.4186191469430923\n",
    "0.4269591748714447\n",
    "0.3958959937095642\n",
    "0.41344760954380033\n",
    "0.4138583242893219\n",
    "0.40633000135421754\n",
    "0.39994949102401733\n",
    "0.3975194424390793\n",
    "0.40272362232208253\n",
    "0.4012870728969574\n",
    "0.40235031843185426\n",
    "0.4019907236099243\n",
    "0.4066860735416412\n",
    "0.3985380917787552\n",
    "0.40268769264221194\n",
    "\n",
    "가장 잘 나온 부분은 0.386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63541ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "num_epochs = 284\n",
    "num_val = len(X_train) // k\n",
    "all_scores = []\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "for i in range(k):\n",
    "#         print('processing fold #', i)\n",
    "\n",
    "    X_val = X_train[i * num_val: (i + 1) * num_val]\n",
    "    y_val = y_train[i * num_val: (i + 1) * num_val]\n",
    "\n",
    "    X_train_part = np.concatenate(\n",
    "        [X_train[:i * num_val],\n",
    "        X_train[(i + 1) * num_val:]],\n",
    "        axis = 0)\n",
    "\n",
    "    y_train_part = np.concatenate(\n",
    "        [y_train[:i * num_val],\n",
    "        y_train[(i + 1) * num_val:]],\n",
    "        axis = 0)\n",
    "\n",
    "    model = build_model()\n",
    "    history = model.fit(X_train_part, y_train_part,\n",
    "             epochs = num_epochs, verbose = 0)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose = 0)\n",
    "    all_scores.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf59fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38668836653232574"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
